# UNet Segmentation

## Goal
The goal of this project is to explore and compare different architectural choices for building a UNet-like model for semantic image segmentation. Specifically, it investigates the impact of different downsampling and upsampling mechanisms, as well as the effectiveness of different loss functions (BCE vs. Dice Loss) on the Oxford-IIIT Pet dataset.

## Approach & Architectures
The project implements four distinct variants of the UNet architecture to isolate the effects of specific components.

### Dataset
- **Dataset:** Oxford-IIIT Pet Dataset
- **Task:** Binary Segmentation (Pet vs. Background/Border)
- **Input Size:** 128x128
- **Preprocessing:** Resize, ToTensor, Nearest Interpolation for masks.

### Model Variants
All models share a similar encoder-decoder structure with skip connections but differ in their specific blocks:

| Model Variant | Downsampling | Upsampling | Loss Function |
| :--- | :--- | :--- | :--- |
| **Model 1** | MaxPool (2x2) | Transposed Conv | BCE With Logits |
| **Model 2** | MaxPool (2x2) | Transposed Conv | Dice Loss |
| **Model 3** | Strided Conv (3x3, stride 2) | Transposed Conv | BCE With Logits |
| **Model 4** | Strided Conv (3x3, stride 2) | Bilinear Interpolation | BCE + Dice Loss |

### Key Architectural Details
*   **ConvBlock:** Standard double convolution (Conv3x3 -> ReLU -> Conv3x3 -> ReLU).
*   **Skip Connections:** Included in all upsampling steps to preserve spatial information.
*   **Safe Alignment:** Upsampling blocks include dynamic resizing to handle potential odd-dimension mismatches during forward pass.

## Training Details
*   **Optimizer:** Adam
*   **Learning Rate:** 1e-4
*   **Batch Size:** 16
*   **Epochs:** 20
*   **Device:** CUDA (if available)

## Test Results
The models were trained for 20 epochs. Below is a summary of the final and best validation losses observed during training:

| Model | Best Val Loss | Final Train Loss | Final Val Loss | Observation |
| :--- | :--- | :--- | :--- | :--- |
| **Model 1** | 0.5712 | 0.3222 | 0.6509 | Baseline performance with BCE. |
| **Model 2** | **0.1719** | **0.1604** | **0.1722** | **Best Performance.** Pure Dice loss proved most effective for this task. |
| **Model 3** | 0.6238 | 0.3929 | 0.6713 | Strided convolutions performed similarly to MaxPool but slightly worse than Model 1. |
| **Model 4** | 0.9171 | 0.4224 | 1.0919 | Bilinear upsampling with mixed loss struggled to converge as well as others. |

*Note: Results are based on the run recorded in `Train_test_notebook.ipynb`.*

## How to Run

### Requirements
Install dependencies:
```bash
pip install -r requirements.txt
```

### Training
To train a specific model variant, run:
```bash
python train.py --model [model1 | model2 | model3 | model4]
```

### Inference / Demo
A Gradio app is provided to visualize and compare the outputs of all trained models:
```bash
python app.py
```
This will launch a web interface where you can upload an image and see the segmentation masks generated by all available models.
